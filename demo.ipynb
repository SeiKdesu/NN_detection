{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from neural_interaction_detection import get_interactions\n",
    "from multilayer_perceptron import MLP, train, get_weights\n",
    "from utils import (\n",
    "    preprocess_data,\n",
    "    get_pairwise_auc,\n",
    "    get_anyorder_R_precision,\n",
    "    set_seed,\n",
    "    print_rankings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_main_effect_nets = True  # toggle this to use \"main effect\" nets\n",
    "num_samples = 1000\n",
    "num_features = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data with ground truth interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def _ellipsoid(X):\n",
    "    # X: (N, n)\n",
    "    n = X.shape[1]\n",
    "    if n == 1:\n",
    "        w = np.array([1.0], dtype=X.dtype)\n",
    "    else:\n",
    "        w = 10.0 ** (6.0 * np.arange(n) / (n - 1))  # [1, 1e6]まで指数的に増加\n",
    "    return np.sum(w * (X**2), axis=1)\n",
    "\n",
    "\n",
    "def _rastrigin(X):\n",
    "    n = X.shape[1]\n",
    "    return 10.0 * n + np.sum(X**2 - 10.0 * np.cos(2.0 * np.pi * X), axis=1)\n",
    "\n",
    "\n",
    "def _ackley(X):\n",
    "    n = X.shape[1]\n",
    "    s1 = np.sum(X**2, axis=1)\n",
    "    s2 = np.sum(np.cos(2.0 * np.pi * X), axis=1)\n",
    "    term1 = -20.0 * np.exp(-0.2 * np.sqrt(s1 / n))\n",
    "    term2 = -np.exp(s2 / n)\n",
    "    return term1 + term2 + 20.0 + np.e\n",
    "\n",
    "\n",
    "def _rosenbrock(X):\n",
    "    # X: (N, n)\n",
    "    # sum_{i=1}^{n-1} [100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2]\n",
    "    xi = X[:, :-1]\n",
    "    xnext = X[:, 1:]\n",
    "    return np.sum(100.0 * (xnext - xi**2) ** 2 + (xi - 1.0) ** 2, axis=1)\n",
    "\n",
    "\n",
    "def synth_func(X):\n",
    "    \"\"\"\n",
    "    X: shape (N, 100)\n",
    "    Returns:\n",
    "      Y: shape (N,)\n",
    "      ground_truth: list[set[int]] (1-indexed variable indices)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim != 2 or X.shape[1] != 100:\n",
    "        raise ValueError(f\"X must be (N, 100). Got {X.shape}\")\n",
    "\n",
    "    X_e = X[:, 0:25]  # 1..25\n",
    "    X_r = X[:, 25:50]  # 26..50\n",
    "    X_a = X[:, 50:75]  # 51..75\n",
    "    X_rb = X[:, 75:100]  # 76..100\n",
    "\n",
    "    Y = _ellipsoid(X_e) + _rastrigin(X_r) + _ackley(X_a) + _rosenbrock(X_rb)\n",
    "\n",
    "    ground_truth = [\n",
    "        set(range(76, 101)),\n",
    "    ]\n",
    "\n",
    "    return Y, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "X = np.random.uniform(low=-1, high=1, size=(num_samples, num_features))\n",
    "Y, ground_truth = synth_func(X)\n",
    "data_loaders = preprocess_data(\n",
    "    X, Y, valid_size=100, test_size=100, std_scale=True, get_torch_loaders=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = MLP(\n",
    "    num_features, [140, 100, 60, 20], use_main_effect_nets=use_main_effect_nets\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train\n",
      "early stopping enabled\n",
      "[epoch 1, total 100] train loss: 3.4727, val loss: 1.0503\n",
      "[epoch 3, total 100] train loss: 1.1290, val loss: 0.9284\n",
      "[epoch 5, total 100] train loss: 0.9798, val loss: 0.8819\n",
      "[epoch 7, total 100] train loss: 0.8218, val loss: 0.7768\n",
      "[epoch 9, total 100] train loss: 0.5839, val loss: 0.4960\n",
      "[epoch 11, total 100] train loss: 0.1865, val loss: 0.1349\n",
      "[epoch 13, total 100] train loss: 0.0822, val loss: 0.0891\n",
      "[epoch 15, total 100] train loss: 0.0501, val loss: 0.0641\n",
      "[epoch 17, total 100] train loss: 0.0296, val loss: 0.0449\n",
      "[epoch 19, total 100] train loss: 0.0201, val loss: 0.0311\n",
      "[epoch 21, total 100] train loss: 0.0148, val loss: 0.0258\n",
      "[epoch 23, total 100] train loss: 0.0128, val loss: 0.0224\n",
      "[epoch 25, total 100] train loss: 0.0100, val loss: 0.0190\n",
      "[epoch 27, total 100] train loss: 0.0105, val loss: 0.0153\n",
      "[epoch 29, total 100] train loss: 0.0076, val loss: 0.0131\n",
      "[epoch 31, total 100] train loss: 0.0067, val loss: 0.0137\n",
      "[epoch 33, total 100] train loss: 0.0093, val loss: 0.0156\n",
      "[epoch 35, total 100] train loss: 0.0061, val loss: 0.0094\n",
      "[epoch 37, total 100] train loss: 0.0056, val loss: 0.0118\n",
      "[epoch 39, total 100] train loss: 0.0044, val loss: 0.0080\n",
      "[epoch 41, total 100] train loss: 0.0044, val loss: 0.0073\n",
      "[epoch 43, total 100] train loss: 0.0038, val loss: 0.0080\n",
      "[epoch 45, total 100] train loss: 0.0038, val loss: 0.0079\n",
      "[epoch 47, total 100] train loss: 0.0036, val loss: 0.0063\n",
      "[epoch 49, total 100] train loss: 0.0029, val loss: 0.0062\n",
      "[epoch 51, total 100] train loss: 0.0029, val loss: 0.0064\n",
      "[epoch 53, total 100] train loss: 0.0029, val loss: 0.0059\n",
      "[epoch 55, total 100] train loss: 0.0030, val loss: 0.0069\n",
      "[epoch 57, total 100] train loss: 0.0024, val loss: 0.0055\n",
      "[epoch 59, total 100] train loss: 0.0024, val loss: 0.0091\n",
      "[epoch 61, total 100] train loss: 0.0039, val loss: 0.0052\n",
      "[epoch 63, total 100] train loss: 0.0042, val loss: 0.0060\n",
      "[epoch 65, total 100] train loss: 0.0031, val loss: 0.0084\n",
      "early stopping!\n",
      "Finished Training. Test loss:  0.004005380906164646\n"
     ]
    }
   ],
   "source": [
    "model, mlp_loss = train(\n",
    "    model, data_loaders, device=device, learning_rate=1e-2, l1_const=5e-5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MLP's learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = get_weights(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect interactions from the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise interactions              Arbitrary-order interactions\n",
      "(np.int64(16), np.int64(84))0.0000                      (np.int64(15), np.int64(18))0.0000        \n",
      "(np.int64(6), np.int64(16))0.0000                      (np.int64(15), np.int64(18), np.int64(92))0.0000        \n",
      "(np.int64(15), np.int64(29))0.0000                      (np.int64(6), np.int64(32))0.0000        \n",
      "(np.int64(6), np.int64(32))0.0000                      (np.int64(15), np.int64(18), np.int64(76), np.int64(92))0.0000        \n",
      "(np.int64(5), np.int64(18))0.0000                      (np.int64(6), np.int64(32), np.int64(37))0.0000        \n",
      "(np.int64(6), np.int64(29))0.0000                      (np.int64(15), np.int64(18), np.int64(35), np.int64(76), np.int64(92))0.0000        \n",
      "(np.int64(5), np.int64(29))0.0000                      (np.int64(3), np.int64(6), np.int64(32), np.int64(37))0.0000        \n",
      "(np.int64(29), np.int64(70))0.0000                      (np.int64(3), np.int64(6), np.int64(32), np.int64(37), np.int64(42))0.0000        \n",
      "(np.int64(29), np.int64(73))0.0000                      (np.int64(15), np.int64(18), np.int64(29), np.int64(35), np.int64(76), np.int64(92))0.0000        \n",
      "(np.int64(6), np.int64(84))0.0000                      (np.int64(15), np.int64(18), np.int64(29), np.int64(35), np.int64(76), np.int64(85), np.int64(92))0.0000        \n"
     ]
    }
   ],
   "source": [
    "anyorder_interactions = get_interactions(model_weights, one_indexed=True)\n",
    "pairwise_interactions = get_interactions(model_weights, pairwise=True, one_indexed=True)\n",
    "\n",
    "\n",
    "print_rankings(pairwise_interactions, anyorder_interactions, top_k=10, spacing=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise AUC 0.5105806451612903 , Any-order R-Precision 0.0\n"
     ]
    }
   ],
   "source": [
    "auc = get_pairwise_auc(pairwise_interactions, ground_truth)\n",
    "r_prec = get_anyorder_R_precision(anyorder_interactions, ground_truth)\n",
    "\n",
    "print(\"Pairwise AUC\", auc, \", Any-order R-Precision\", r_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
