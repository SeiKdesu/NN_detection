{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from neural_interaction_detection import get_interactions\n",
    "from multilayer_perceptron import MLP, train, get_weights\n",
    "from utils import (\n",
    "    preprocess_data,\n",
    "    get_pairwise_auc,\n",
    "    get_anyorder_R_precision,\n",
    "    set_seed,\n",
    "    print_rankings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_main_effect_nets = True  # toggle this to use \"main effect\" nets\n",
    "num_samples = 1000\n",
    "num_features = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data with ground truth interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "BLOCK_DIM = 25\n",
    "NUM_BLOCKS = 4\n",
    "TOTAL_DIM = BLOCK_DIM * NUM_BLOCKS\n",
    "\n",
    "# ---- Local benchmark functions (no py-benchmark dependency) ----\n",
    "# All functions accept X with shape (N, dim) and return (N,)\n",
    "\n",
    "def _sphere(X):\n",
    "    return np.sum(X ** 2, axis=1)\n",
    "\n",
    "\n",
    "def _rastrigin(X):\n",
    "    n = X.shape[1]\n",
    "    return 10.0 * n + np.sum(X ** 2 - 10.0 * np.cos(2.0 * np.pi * X), axis=1)\n",
    "\n",
    "\n",
    "def _ackley(X):\n",
    "    n = X.shape[1]\n",
    "    s1 = np.sum(X ** 2, axis=1)\n",
    "    s2 = np.sum(np.cos(2.0 * np.pi * X), axis=1)\n",
    "    term1 = -20.0 * np.exp(-0.2 * np.sqrt(s1 / n))\n",
    "    term2 = -np.exp(s2 / n)\n",
    "    return term1 + term2 + 20.0 + np.e\n",
    "\n",
    "\n",
    "def _rosenbrock(X):\n",
    "    xi = X[:, :-1]\n",
    "    xnext = X[:, 1:]\n",
    "    return np.sum(100.0 * (xnext - xi ** 2) ** 2 + (xi - 1.0) ** 2, axis=1)\n",
    "\n",
    "\n",
    "def _griewank(X):\n",
    "    n = X.shape[1]\n",
    "    sum_term = np.sum(X ** 2, axis=1) / 4000.0\n",
    "    i = np.arange(1, n + 1)\n",
    "    prod_term = np.prod(np.cos(X / np.sqrt(i)), axis=1)\n",
    "    return sum_term - prod_term + 1.0\n",
    "\n",
    "\n",
    "def _schwefel(X):\n",
    "    n = X.shape[1]\n",
    "    return 418.9829 * n - np.sum(X * np.sin(np.sqrt(np.abs(X))), axis=1)\n",
    "\n",
    "\n",
    "def _levy(X):\n",
    "    w = 1 + (X - 1) / 4\n",
    "    term1 = np.sin(np.pi * w[:, 0]) ** 2\n",
    "    term3 = (w[:, -1] - 1) ** 2 * (1 + np.sin(2 * np.pi * w[:, -1]) ** 2)\n",
    "    wi = w[:, :-1]\n",
    "    term2 = np.sum((wi - 1) ** 2 * (1 + 10 * np.sin(np.pi * wi + 1) ** 2), axis=1)\n",
    "    return term1 + term2 + term3\n",
    "\n",
    "\n",
    "def _zakharov(X):\n",
    "    i = np.arange(1, X.shape[1] + 1)\n",
    "    sum1 = np.sum(X ** 2, axis=1)\n",
    "    sum2 = np.sum(0.5 * i * X, axis=1)\n",
    "    return sum1 + sum2 ** 2 + sum2 ** 4\n",
    "\n",
    "\n",
    "def _michalewicz(X, m=10):\n",
    "    i = np.arange(1, X.shape[1] + 1)\n",
    "    return -np.sum(np.sin(X) * (np.sin(i * X ** 2 / np.pi) ** (2 * m)), axis=1)\n",
    "\n",
    "\n",
    "def _dixon_price(X):\n",
    "    x1 = X[:, 0]\n",
    "    i = np.arange(2, X.shape[1] + 1)\n",
    "    xi = X[:, 1:]\n",
    "    term1 = (x1 - 1) ** 2\n",
    "    term2 = np.sum(i * (2 * xi ** 2 - X[:, :-1]) ** 2, axis=1)\n",
    "    return term1 + term2\n",
    "\n",
    "\n",
    "def _sum_squares(X):\n",
    "    i = np.arange(1, X.shape[1] + 1)\n",
    "    return np.sum(i * X ** 2, axis=1)\n",
    "\n",
    "\n",
    "def _bent_cigar(X):\n",
    "    return X[:, 0] ** 2 + 1e6 * np.sum(X[:, 1:] ** 2, axis=1)\n",
    "\n",
    "\n",
    "def _discus(X):\n",
    "    return 1e6 * X[:, 0] ** 2 + np.sum(X[:, 1:] ** 2, axis=1)\n",
    "\n",
    "\n",
    "def _weierstrass(X, a=0.5, b=3.0, k_max=20):\n",
    "    i = np.arange(0, k_max + 1)\n",
    "    term1 = np.sum((a ** i) * np.cos(2 * np.pi * (b ** i) * (X[:, :, None] + 0.5)), axis=2)\n",
    "    term1 = np.sum(term1, axis=1)\n",
    "    term2 = X.shape[1] * np.sum((a ** i) * np.cos(2 * np.pi * (b ** i) * 0.5))\n",
    "    return term1 - term2\n",
    "\n",
    "\n",
    "def _ellipsoid(X):\n",
    "    i = np.arange(1, X.shape[1] + 1)\n",
    "    return np.sum((1e6 ** ((i - 1) / (X.shape[1] - 1))) * X ** 2, axis=1)\n",
    "\n",
    "\n",
    "def _alpine1(X):\n",
    "    return np.sum(np.abs(X * np.sin(X) + 0.1 * X), axis=1)\n",
    "\n",
    "\n",
    "def _alpine2(X):\n",
    "    return np.prod(np.sqrt(np.abs(X)) * np.sin(X), axis=1) * -1.0\n",
    "\n",
    "\n",
    "def _katsuura(X):\n",
    "    n = X.shape[1]\n",
    "    i = np.arange(1, n + 1)\n",
    "    j = np.arange(1, 33)\n",
    "    term = np.sum(np.abs(2 ** j * X[:, :, None] - np.round(2 ** j * X[:, :, None])) / 2 ** j, axis=2)\n",
    "    prod = np.prod((1 + i * term) ** (10 / n ** 1.2), axis=1)\n",
    "    return prod - 1\n",
    "\n",
    "\n",
    "def _salomon(X):\n",
    "    r = np.sqrt(np.sum(X ** 2, axis=1))\n",
    "    return 1 - np.cos(2 * np.pi * r) + 0.1 * r\n",
    "\n",
    "\n",
    "def _whitley(X):\n",
    "    n = X.shape[1]\n",
    "    total = np.zeros(X.shape[0])\n",
    "    for i in range(n):\n",
    "        xi = X[:, i][:, None]\n",
    "        for j in range(n):\n",
    "            xj = X[:, j][:, None]\n",
    "            temp = 100 * (xi ** 2 - xj) ** 2 + (1 - xj) ** 2\n",
    "            total += (temp ** 2 / 4000.0 - np.cos(temp) + 1).reshape(-1)\n",
    "    return total\n",
    "\n",
    "\n",
    "def _bohachevsky(X):\n",
    "    x1 = X[:, 0]\n",
    "    x2 = X[:, 1]\n",
    "    return x1 ** 2 + 2 * x2 ** 2 - 0.3 * np.cos(3 * np.pi * x1) - 0.4 * np.cos(4 * np.pi * x2) + 0.7\n",
    "\n",
    "\n",
    "def _perm(X, beta=10):\n",
    "    n = X.shape[1]\n",
    "    j = np.arange(1, n + 1)\n",
    "    total = np.zeros(X.shape[0])\n",
    "    for i in range(1, n + 1):\n",
    "        term = np.sum((j ** i + beta) * ((X / j) ** i - 1), axis=1)\n",
    "        total += term ** 2\n",
    "    return total\n",
    "\n",
    "\n",
    "def _trid(X):\n",
    "    term1 = np.sum((X - 1) ** 2, axis=1)\n",
    "    term2 = np.sum(X[:, 1:] * X[:, :-1], axis=1)\n",
    "    return term1 - term2\n",
    "\n",
    "\n",
    "def _powell(X):\n",
    "    # assumes dim is multiple of 4; for 25D, we wrap last block\n",
    "    Xp = X.copy()\n",
    "    if Xp.shape[1] % 4 != 0:\n",
    "        pad = 4 - (Xp.shape[1] % 4)\n",
    "        Xp = np.pad(Xp, ((0, 0), (0, pad)), mode=\"wrap\")\n",
    "    total = np.zeros(Xp.shape[0])\n",
    "    for i in range(0, Xp.shape[1], 4):\n",
    "        x1, x2, x3, x4 = Xp[:, i], Xp[:, i + 1], Xp[:, i + 2], Xp[:, i + 3]\n",
    "        total += (x1 + 10 * x2) ** 2 + 5 * (x3 - x4) ** 2 + (x2 - 2 * x3) ** 4 + 10 * (x1 - x4) ** 4\n",
    "    return total\n",
    "\n",
    "\n",
    "def _styblinski_tang(X):\n",
    "    return 0.5 * np.sum(X ** 4 - 16 * X ** 2 + 5 * X, axis=1)\n",
    "\n",
    "\n",
    "def _quartic(X):\n",
    "    i = np.arange(1, X.shape[1] + 1)\n",
    "    return np.sum(i * X ** 4, axis=1)\n",
    "\n",
    "\n",
    "def _brown(X):\n",
    "    xi = X[:, :-1]\n",
    "    xnext = X[:, 1:]\n",
    "    return np.sum((xi ** 2) ** (xnext ** 2 + 1) + (xnext ** 2) ** (xi ** 2 + 1), axis=1)\n",
    "\n",
    "\n",
    "def _ridge(X):\n",
    "    return X[:, 0] + 100 * np.sqrt(np.sum(X[:, 1:] ** 2, axis=1))\n",
    "\n",
    "\n",
    "FUNCTIONS = {\n",
    "    \"sphere\": _sphere,\n",
    "    \"rastrigin\": _rastrigin,\n",
    "    \"ackley\": _ackley,\n",
    "    \"rosenbrock\": _rosenbrock,\n",
    "    \"griewank\": _griewank,\n",
    "    \"schwefel\": _schwefel,\n",
    "    \"levy\": _levy,\n",
    "    \"zakharov\": _zakharov,\n",
    "    \"michalewicz\": _michalewicz,\n",
    "    \"dixon_price\": _dixon_price,\n",
    "    \"sum_squares\": _sum_squares,\n",
    "    \"bent_cigar\": _bent_cigar,\n",
    "    \"discus\": _discus,\n",
    "    \"weierstrass\": _weierstrass,\n",
    "    \"ellipsoid\": _ellipsoid,\n",
    "    \"alpine1\": _alpine1,\n",
    "    \"alpine2\": _alpine2,\n",
    "    \"katsuura\": _katsuura,\n",
    "    \"salomon\": _salomon,\n",
    "    \"whitley\": _whitley,\n",
    "    \"bohachevsky\": _bohachevsky,\n",
    "    \"perm\": _perm,\n",
    "    \"trid\": _trid,\n",
    "    \"powell\": _powell,\n",
    "    \"styblinski_tang\": _styblinski_tang,\n",
    "    \"quartic\": _quartic,\n",
    "    \"brown\": _brown,\n",
    "    \"ridge\": _ridge,\n",
    "}\n",
    "\n",
    "# Choose 25 names for the pool\n",
    "POOL_NAMES = [\n",
    "    \"sphere\",\n",
    "    \"rastrigin\",\n",
    "    \"ackley\",\n",
    "    \"rosenbrock\",\n",
    "    \"griewank\",\n",
    "    \"schwefel\",\n",
    "    \"levy\",\n",
    "    \"zakharov\",\n",
    "    \"michalewicz\",\n",
    "    \"dixon_price\",\n",
    "    \"sum_squares\",\n",
    "    \"bent_cigar\",\n",
    "    \"discus\",\n",
    "    \"weierstrass\",\n",
    "    \"ellipsoid\",\n",
    "    \"alpine1\",\n",
    "    \"alpine2\",\n",
    "    \"katsuura\",\n",
    "    \"salomon\",\n",
    "    \"whitley\",\n",
    "    \"bohachevsky\",\n",
    "    \"perm\",\n",
    "    \"trid\",\n",
    "    \"powell\",\n",
    "    \"styblinski_tang\",\n",
    "]\n",
    "\n",
    "\n",
    "def _random_rotation_matrix(dim, rng):\n",
    "    H = rng.normal(size=(dim, dim))\n",
    "    Q, _ = np.linalg.qr(H)\n",
    "    if np.linalg.det(Q) < 0:\n",
    "        Q[:, 0] *= -1\n",
    "    return Q\n",
    "\n",
    "\n",
    "def _resolve_shift(shift, rng, dim, scale):\n",
    "    if shift is None or shift is False:\n",
    "        return None\n",
    "    if isinstance(shift, str):\n",
    "        if shift == \"random\":\n",
    "            return rng.uniform(-scale, scale, size=dim)\n",
    "        raise ValueError(f\"Unknown shift spec: {shift}\")\n",
    "    shift = np.asarray(shift, dtype=float)\n",
    "    if shift.shape != (dim,):\n",
    "        raise ValueError(f\"shift must be shape ({dim},), got {shift.shape}\")\n",
    "    return shift\n",
    "\n",
    "\n",
    "def _resolve_rotation(rotate, rng, dim):\n",
    "    if rotate is None or rotate is False:\n",
    "        return None\n",
    "    if rotate is True or rotate == \"random\":\n",
    "        return _random_rotation_matrix(dim, rng)\n",
    "    rotate = np.asarray(rotate, dtype=float)\n",
    "    if rotate.shape != (dim, dim):\n",
    "        raise ValueError(f\"rotation must be shape ({dim}, {dim}), got {rotate.shape}\")\n",
    "    return rotate\n",
    "\n",
    "\n",
    "def _apply_transform(X, shift=None, rotation=None):\n",
    "    X_t = X\n",
    "    if shift is not None:\n",
    "        X_t = X_t - shift\n",
    "    if rotation is not None:\n",
    "        X_t = X_t @ rotation\n",
    "    return X_t\n",
    "\n",
    "\n",
    "def make_pool_specs(names, rotate=True, shift=\"random\", seed_base=0, weight=1.0, interaction=True):\n",
    "    specs = []\n",
    "    for i, name in enumerate(names):\n",
    "        if name not in FUNCTIONS:\n",
    "            raise ValueError(f\"Unknown function name: {name}\")\n",
    "        specs.append(\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"rotate\": rotate,\n",
    "                \"shift\": shift,\n",
    "                \"seed\": seed_base + i,\n",
    "                \"weight\": weight,\n",
    "                \"interaction\": interaction,\n",
    "            }\n",
    "        )\n",
    "    return specs\n",
    "\n",
    "\n",
    "def build_benchmark_pool(specs, dim, seed=123, shift_scale=1.0):\n",
    "    rng_master = np.random.default_rng(seed)\n",
    "\n",
    "    pool = []\n",
    "    for spec in specs:\n",
    "        spec = dict(spec)\n",
    "        rng = np.random.default_rng(spec.get(\"seed\", rng_master.integers(0, 2**32 - 1)))\n",
    "        shift = _resolve_shift(spec.get(\"shift\", None), rng, dim, shift_scale)\n",
    "        rotation = _resolve_rotation(spec.get(\"rotate\", False), rng, dim)\n",
    "\n",
    "        fn = FUNCTIONS[spec[\"name\"]]\n",
    "        pool.append(\n",
    "            {\n",
    "                \"name\": spec[\"name\"],\n",
    "                \"fn\": fn,\n",
    "                \"shift\": shift,\n",
    "                \"rotation\": rotation,\n",
    "                \"weight\": spec.get(\"weight\", 1.0),\n",
    "                \"interaction\": spec.get(\"interaction\", True),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pool\n",
    "\n",
    "\n",
    "def indices_from_names(pool, names):\n",
    "    name_to_index = {spec[\"name\"]: i for i, spec in enumerate(pool)}\n",
    "    missing = [n for n in names if n not in name_to_index]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Names not in pool: {missing}\")\n",
    "    return [name_to_index[n] for n in names]\n",
    "\n",
    "\n",
    "def make_composite_objective(pool, selected_indices, block_dim=BLOCK_DIM, num_blocks=NUM_BLOCKS):\n",
    "    selected_indices = list(selected_indices)\n",
    "    if len(selected_indices) != num_blocks:\n",
    "        raise ValueError(f\"selected_indices must be length {num_blocks}\")\n",
    "\n",
    "    def _objective(X):\n",
    "        X = np.asarray(X)\n",
    "        if X.ndim != 2 or X.shape[1] != block_dim * num_blocks:\n",
    "            raise ValueError(f\"X must be (N, {block_dim * num_blocks}). Got {X.shape}\")\n",
    "\n",
    "        Y = np.zeros(X.shape[0], dtype=float)\n",
    "        ground_truth = []\n",
    "        for block_i, pool_i in enumerate(selected_indices):\n",
    "            spec = pool[pool_i]\n",
    "            X_block = X[:, block_i * block_dim : (block_i + 1) * block_dim]\n",
    "            X_block = _apply_transform(X_block, spec[\"shift\"], spec[\"rotation\"])\n",
    "            Y = Y + spec[\"weight\"] * spec[\"fn\"](X_block)\n",
    "\n",
    "            if spec.get(\"interaction\", True):\n",
    "                start = block_i * block_dim + 1\n",
    "                end = (block_i + 1) * block_dim + 1\n",
    "                ground_truth.append(set(range(start, end)))\n",
    "\n",
    "        return Y, ground_truth\n",
    "\n",
    "    return _objective\n",
    "\n",
    "\n",
    "# ---- User-configurable pool and selection ----\n",
    "POOL_SPECS = make_pool_specs(POOL_NAMES, rotate=True, shift=\"random\", seed_base=0)\n",
    "BENCHMARK_POOL = build_benchmark_pool(POOL_SPECS, dim=BLOCK_DIM, seed=123, shift_scale=1.0)\n",
    "\n",
    "# Select 4 functions (each 25D) to compose a 100D objective.\n",
    "# Option A: select by indices\n",
    "SELECTED_POOL_INDICES = [0, 1, 2, 3]\n",
    "\n",
    "# Option B: select by names (uncomment if you prefer names and have unique names)\n",
    "# SELECTED_POOL_NAMES = [\"sphere\", \"rastrigin\", \"ackley\", \"rosenbrock\"]\n",
    "# SELECTED_POOL_INDICES = indices_from_names(BENCHMARK_POOL, SELECTED_POOL_NAMES)\n",
    "\n",
    "synth_func = make_composite_objective(BENCHMARK_POOL, SELECTED_POOL_INDICES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "X = np.random.uniform(low=-1, high=1, size=(num_samples, num_features))\n",
    "Y, ground_truth = synth_func(X)\n",
    "data_loaders = preprocess_data(\n",
    "    X, Y, valid_size=100, test_size=100, std_scale=True, get_torch_loaders=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = MLP(\n",
    "    num_features, [140, 100, 60, 20], use_main_effect_nets=use_main_effect_nets\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train\n",
      "early stopping enabled\n",
      "[epoch 1, total 100] train loss: 3.4727, val loss: 1.0503\n",
      "[epoch 3, total 100] train loss: 1.1290, val loss: 0.9284\n",
      "[epoch 5, total 100] train loss: 0.9798, val loss: 0.8819\n",
      "[epoch 7, total 100] train loss: 0.8218, val loss: 0.7768\n",
      "[epoch 9, total 100] train loss: 0.5839, val loss: 0.4960\n",
      "[epoch 11, total 100] train loss: 0.1865, val loss: 0.1349\n",
      "[epoch 13, total 100] train loss: 0.0822, val loss: 0.0891\n",
      "[epoch 15, total 100] train loss: 0.0501, val loss: 0.0641\n",
      "[epoch 17, total 100] train loss: 0.0296, val loss: 0.0449\n",
      "[epoch 19, total 100] train loss: 0.0201, val loss: 0.0311\n",
      "[epoch 21, total 100] train loss: 0.0148, val loss: 0.0258\n",
      "[epoch 23, total 100] train loss: 0.0128, val loss: 0.0224\n",
      "[epoch 25, total 100] train loss: 0.0100, val loss: 0.0190\n",
      "[epoch 27, total 100] train loss: 0.0105, val loss: 0.0153\n",
      "[epoch 29, total 100] train loss: 0.0076, val loss: 0.0131\n",
      "[epoch 31, total 100] train loss: 0.0067, val loss: 0.0137\n",
      "[epoch 33, total 100] train loss: 0.0093, val loss: 0.0156\n",
      "[epoch 35, total 100] train loss: 0.0061, val loss: 0.0094\n",
      "[epoch 37, total 100] train loss: 0.0056, val loss: 0.0118\n",
      "[epoch 39, total 100] train loss: 0.0044, val loss: 0.0080\n",
      "[epoch 41, total 100] train loss: 0.0044, val loss: 0.0073\n",
      "[epoch 43, total 100] train loss: 0.0038, val loss: 0.0080\n",
      "[epoch 45, total 100] train loss: 0.0038, val loss: 0.0079\n",
      "[epoch 47, total 100] train loss: 0.0036, val loss: 0.0063\n",
      "[epoch 49, total 100] train loss: 0.0029, val loss: 0.0062\n",
      "[epoch 51, total 100] train loss: 0.0029, val loss: 0.0064\n",
      "[epoch 53, total 100] train loss: 0.0029, val loss: 0.0059\n",
      "[epoch 55, total 100] train loss: 0.0030, val loss: 0.0069\n",
      "[epoch 57, total 100] train loss: 0.0024, val loss: 0.0055\n",
      "[epoch 59, total 100] train loss: 0.0024, val loss: 0.0091\n",
      "[epoch 61, total 100] train loss: 0.0039, val loss: 0.0052\n",
      "[epoch 63, total 100] train loss: 0.0042, val loss: 0.0060\n",
      "[epoch 65, total 100] train loss: 0.0031, val loss: 0.0084\n",
      "early stopping!\n",
      "Finished Training. Test loss:  0.004005380906164646\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "train_start = time.perf_counter()\n",
    "model, mlp_loss = train(\n",
    "    model, data_loaders, device=device, learning_rate=1e-2, l1_const=5e-5, verbose=True\n",
    ")\n",
    "train_seconds = time.perf_counter() - train_start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MLP's learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = get_weights(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect interactions from the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise interactions              Arbitrary-order interactions\n",
      "(np.int64(16), np.int64(84))0.0000                      (np.int64(15), np.int64(18))0.0000        \n",
      "(np.int64(6), np.int64(16))0.0000                      (np.int64(15), np.int64(18), np.int64(92))0.0000        \n",
      "(np.int64(15), np.int64(29))0.0000                      (np.int64(6), np.int64(32))0.0000        \n",
      "(np.int64(6), np.int64(32))0.0000                      (np.int64(15), np.int64(18), np.int64(76), np.int64(92))0.0000        \n",
      "(np.int64(5), np.int64(18))0.0000                      (np.int64(6), np.int64(32), np.int64(37))0.0000        \n",
      "(np.int64(6), np.int64(29))0.0000                      (np.int64(15), np.int64(18), np.int64(35), np.int64(76), np.int64(92))0.0000        \n",
      "(np.int64(5), np.int64(29))0.0000                      (np.int64(3), np.int64(6), np.int64(32), np.int64(37))0.0000        \n",
      "(np.int64(29), np.int64(70))0.0000                      (np.int64(3), np.int64(6), np.int64(32), np.int64(37), np.int64(42))0.0000        \n",
      "(np.int64(29), np.int64(73))0.0000                      (np.int64(15), np.int64(18), np.int64(29), np.int64(35), np.int64(76), np.int64(92))0.0000        \n",
      "(np.int64(6), np.int64(84))0.0000                      (np.int64(15), np.int64(18), np.int64(29), np.int64(35), np.int64(76), np.int64(85), np.int64(92))0.0000        \n"
     ]
    }
   ],
   "source": [
    "anyorder_interactions = get_interactions(model_weights, one_indexed=True)\n",
    "pairwise_interactions = get_interactions(model_weights, pairwise=True, one_indexed=True)\n",
    "\n",
    "\n",
    "print_rankings(pairwise_interactions, anyorder_interactions, top_k=10, spacing=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise AUC 0.5105806451612903 , Any-order R-Precision 0.0\n"
     ]
    }
   ],
   "source": [
    "auc = get_pairwise_auc(pairwise_interactions, ground_truth)\n",
    "r_prec = get_anyorder_R_precision(anyorder_interactions, ground_truth)\n",
    "\n",
    "print(\"Pairwise AUC\", auc, \", Any-order R-Precision\", r_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "result_dir = \"result\"\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "result_path = os.path.join(result_dir, \"benchmark_results.csv\")\n",
    "\n",
    "selected_names = [BENCHMARK_POOL[i][\"name\"] for i in SELECTED_POOL_INDICES]\n",
    "selected_resolved_names = [BENCHMARK_POOL[i].get(\"resolved_name\", BENCHMARK_POOL[i][\"name\"]) for i in SELECTED_POOL_INDICES]\n",
    "record = {\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"selected_indices\": json.dumps(SELECTED_POOL_INDICES),\n",
    "    \"selected_names\": json.dumps(selected_names),\n",
    "    \"selected_resolved_names\": json.dumps(selected_resolved_names),\n",
    "    \"train_seconds\": train_seconds,\n",
    "    \"pairwise_auc\": auc,\n",
    "    \"anyorder_r_precision\": r_prec,\n",
    "}\n",
    "\n",
    "write_header = not os.path.exists(result_path)\n",
    "with open(result_path, \"a\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=record.keys())\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerow(record)\n",
    "\n",
    "print(f\"Saved results to {result_path}\")\n",
    "record\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}